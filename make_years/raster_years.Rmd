---
title: "years_raster"
output: html_document
---

```{r}
library(tidyverse)
library(readxl)
library(plotly)
```

```{r}
base_data_all_years <- readRDS("./n1_n2_cleaned_cases.RDS") 

one_only <- subset(base_data_all_years, date < as.Date("2021-06-29"))
two_only <- subset(base_data_all_years, date >= as.Date("2021-06-29"))
```

```{r}
saveRDS(one_only, "./year1.RDS")
saveRDS(two_only, "./year2.RDS")
```



```{r}
base_data_year1 <- readRDS("./year1.RDS")
base_data_year2 <- readRDS("./year2.RDS")
```

```{r}
make_rejoin <- function(df) {
final_data <- df %>% mutate(log_copy_per_L = log10(mean_copy_num_L)) %>%
  rename(Facility = wrf) %>%
  mutate(Facility = recode(Facility, 
                           "NO" = "WRF A",
                           "MI" = "WRF B",
                           "CC" = "WRF C"))

only_positives <- subset(final_data, (!is.na(final_data$Facility)))
only_n1 <- subset(only_positives, target == "N1")
only_n2 <- subset(only_positives, target == "N2")


only_n1 <- only_n1[!(only_n1$Facility == "WRF A" & only_n1$date == "2020-11-02"), ]
only_n2 <- only_n2[!(only_n2$Facility == "WRF A" & only_n2$date == "2020-11-02"), ]

#n1
smooth_n1 <- only_n1 %>% select(-c(Facility)) %>% 
  group_by(date, cases_cum_clarke, new_cases_clarke, X7_day_ave_clarke) %>%
  summarize(sum_copy_num_L = sum(mean_total_copies)) %>%
  ungroup() %>%
  mutate(target = "N1")

#n2
smooth_n2 <- only_n2 %>% select(-c(Facility)) %>% 
  group_by(date, cases_cum_clarke, new_cases_clarke, X7_day_ave_clarke) %>%
  summarize(sum_copy_num_L = sum(mean_total_copies)) %>%
  ungroup() %>%
  mutate(target = "N2")

#Copy code to recreate smoothing plots then rejoin and average to match methods on website
rejoin <- full_join(smooth_n1, smooth_n2) %>%
  select(c(date, sum_copy_num_L)) %>%
  group_by(date) %>%
  summarize_if(is.numeric, mean) %>%
  ungroup() %>%
  mutate(log_sum_copies_both = log10(sum_copy_num_L))

rejoin <- rejoin %>% 
  mutate(new = 1) %>%
  mutate(new2 = 2) %>%
  rename(sum_copies_both = sum_copy_num_L)

return(rejoin)
}

```

```{r}
rejoin_year1 <- make_rejoin(base_data_year1)
rejoin_year2 <- make_rejoin(base_data_year2)

rejoin_both <- make_rejoin(base_data_all_years)
```

```{r}
saveRDS(rejoin_year1, "./rejoin_year1.rds")
saveRDS(rejoin_year2, "./rejoin_year2.rds")
saveRDS(rejoin_both, "./rejoin_both.rds")

```


**************************************************************************************************************************************
Remake full data for percentiles

```{r}
rejoin_all <- rbind(rejoin_year1, rejoin_year2)
```



```{r}
#**************************************************************************************************************
#***********************************Update point range with new x value****************************************
lines <- rejoin_all %>% ggplot() +
  geom_linerange(aes(x = log_sum_copies_both, ymin = new, ymax = new2)) + 
  scale_y_continuous(breaks = seq(0.95, 2.05, 1), limits = c(0.95, 2.05)) +
  annotate("pointrange", x = 13.12166, y = 1.5, ymin = 0.95, ymax = 2.05, color = "red", size =1) +
  theme_classic() +
  xlab("Log Viral Load")

lines <- lines +   
  theme(axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank(),
        axis.line.y = element_blank()) +
  annotate("text", x = 11.3, y = 0.95, label = "Lowest Observed") +
  annotate("text", x = 14.2, y = 0.95, label = "Highest Observed") +
  labs(caption = "This Week's Viral Load 1.32e+13 Copies")

lines
```

Combined percentile =
average the log_sum_both values for each day then take log10() of that value

do not average the log transformed values. 




```{r}
perc.rank <- function(x, xo)  length(x[x <= xo])/length(x)*100

perc.rank(rejoin_all$log_sum_copies_both, 13.12166)
```
mutate(percrank=rank(value)/length(value))





